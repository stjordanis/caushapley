\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{lundberg2020local}
\citation{shapley1953value}
\citation{lipovetsky2001analysis}
\citation{vstrumbelj2014explaining}
\citation{lundberg2017unified}
\citation{ribeiro2016should}
\citation{sloman2005causal}
\citation{lombrozo2017causal}
\citation{sober1988apportioning}
\citation{gerstenberg2012noisy}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{wachter2017counterfactual}
\citation{vstrumbelj2014explaining}
\citation{datta2016algorithmic}
\citation{lundberg2017unified}
\citation{aas2019explaining}
\citation{janzing2019feature}
\citation{datta2016algorithmic}
\citation{pearl2012calculus}
\citation{lundberg2020local}
\citation{frye2019asymmetric}
\citation{aas2019explaining}
\citation{lauritzen2002chain}
\citation{shapley1953value}
\citation{pearl1995causal}
\@writefile{toc}{\contentsline {section}{\numberline {2}A causal interpretation of Shapley values}{2}{section.2}}
\newlabel{sec:interpretation}{{2}{2}{A causal interpretation of Shapley values}{section.2}{}}
\newlabel{eq:efficiency}{{1}{2}{A causal interpretation of Shapley values}{equation.2.1}{}}
\newlabel{eq:contperm}{{2}{2}{A causal interpretation of Shapley values}{equation.2.2}{}}
\newlabel{eq:valuedef}{{3}{2}{A causal interpretation of Shapley values}{equation.2.3}{}}
\citation{shapley1953value}
\citation{frye2019asymmetric}
\citation{aas2019explaining}
\citation{lundberg2018consistent}
\citation{datta2016algorithmic}
\citation{janzing2019feature}
\citation{lundberg2020local}
\citation{janzing2019feature}
\citation{datta2016algorithmic}
\citation{janzing2019feature}
\citation{lundberg2020local}
\citation{sober1988apportioning}
\citation{frye2019asymmetric}
\citation{frye2019asymmetric}
\newlabel{eq:shapperm}{{4}{3}{A causal interpretation of Shapley values}{equation.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Decomposing Shapley values into direct and indirect effects}{3}{section.3}}
\citation{kahneman1986norm}
\citation{merrick2019explanation}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Direct and indirect Shapley values for four causal models with the same observational distribution over features (such that $\mathbb  {E}[X_1] = \mathbb  {E}[X_2] = 0$ and $\mathbb  {E}[X_2|x_1] = \alpha x_1$), yet a different causal structure. We assume a linear model that happens to ignore the first feature: $f(x_1,x_2) = \beta x_2$. The bottom table gives for each of the four causal models on the left the marginal, conditional, and causal Shapley values, where the latter two are further split up in symmetric and asymmetric. Each letter in the bottom table corresponds to one of the patterns of direct and indirect effects detailed in the top table: `direct' ({\em  D}, only direct effects), `evenly split' ({\em  E}, credit for an indirect effect split evenly between the features), and `root cause' ({\em  R}, all credit for the indirect effect goes to the root cause).\relax }}{4}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:fourmodels}{{1}{4}{Direct and indirect Shapley values for four causal models with the same observational distribution over features (such that $\expectation [X_1] = \expectation [X_2] = 0$ and $\expectation [X_2|x_1] = \alpha x_1$), yet a different causal structure. We assume a linear model that happens to ignore the first feature: $f(x_1,x_2) = \beta x_2$. The bottom table gives for each of the four causal models on the left the marginal, conditional, and causal Shapley values, where the latter two are further split up in symmetric and asymmetric. Each letter in the bottom table corresponds to one of the patterns of direct and indirect effects detailed in the top table: `direct' (\patd , only direct effects), `evenly split' (\pats , credit for an indirect effect split evenly between the features), and `root cause' (\pata , all credit for the indirect effect goes to the root cause).\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Shapley values for different causal structures}{4}{section.4}}
\newlabel{sec:toymodels}{{4}{4}{Shapley values for different causal structures}{section.4}{}}
\citation{datta2016algorithmic}
\citation{janzing2019feature}
\citation{lundberg2020local}
\citation{aas2019explaining}
\citation{frye2019asymmetric}
\citation{frye2019asymmetric}
\citation{spellman1997crediting}
\citation{icard2017normality}
\citation{lewis1974causation}
\citation{pearl2012calculus}
\citation{lauritzen2002chain}
\citation{lauritzen2002chain}
\@writefile{toc}{\contentsline {section}{\numberline {5}A practical implementation with causal chain graphs}{5}{section.5}}
\newlabel{eq:interventional}{{5}{5}{A practical implementation with causal chain graphs}{equation.5.5}{}}
\citation{lauritzen2002chain}
\citation{pearl2012calculus}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces From partial ordering to causal chain graph. Features on an equal footing are combined into a fully connected chain component. How to handle interventions within each component depends on the generative process that best explains the (surplus) dependencies. In this example, the dependencies in chain components $\tau _1$ and $\tau _3$ are assumed to be the result of a common confounder, and those in $\tau _2$ of mutual interactions.\relax }}{6}{figure.caption.3}}
\newlabel{fig:chaingraph}{{2}{6}{From partial ordering to causal chain graph. Features on an equal footing are combined into a fully connected chain component. How to handle interventions within each component depends on the generative process that best explains the (surplus) dependencies. In this example, the dependencies in chain components $\tau _1$ and $\tau _3$ are assumed to be the result of a common confounder, and those in $\tau _2$ of mutual interactions.\relax }{figure.caption.3}{}}
\newlabel{eq:chaininterventional}{{7}{6}{}{equation.5.6}{}}
\citation{aas2019explaining}
\citation{frye2019asymmetric}
\citation{aas2019explaining}
\citation{aas2019explaining}
\citation{frye2019asymmetric}
\citation{fanaee2013bikerental}
\citation{aas2019explaining}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Bike shares in Washington, D.C.\ in 2011-2012 (top left; colorbar with temperature in degrees Celsius). Sina plot of causal Shapley values for a trained XGBoost model, where the top three date-related variables are considered to be a potential cause of the four weather-related variables (right). Scatter plots of marginal (MSV) versus causal Shapley values (CSV) for temperature ({\em  temp}) and one of the seasonal variables ({\em  cosyear}) show that MSVs almost purely explain the predictions based on temperature, whereas CSVs also give credit to season (bottom left).\relax }}{7}{figure.caption.4}}
\newlabel{fig:trendplot}{{3}{7}{Bike shares in Washington, D.C.\ in 2011-2012 (top left; colorbar with temperature in degrees Celsius). Sina plot of causal Shapley values for a trained XGBoost model, where the top three date-related variables are considered to be a potential cause of the four weather-related variables (right). Scatter plots of marginal (MSV) versus causal Shapley values (CSV) for temperature ({\em temp}) and one of the seasonal variables ({\em cosyear}) show that MSVs almost purely explain the predictions based on temperature, whereas CSVs also give credit to season (bottom left).\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Illustration on real-world data}{7}{section.6}}
\citation{frye2019asymmetric}
\citation{lundberg2017unified}
\citation{lundberg2020local}
\citation{wachter2017counterfactual}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Asymmetric (conditional), (symmetric) causal and marginal Shapley values for two different days, one in October (brown) and one in December (gray) with more or less the same temperature of 13 degrees Celsius. Asymmetric Shapley values focus on the root cause, marginal Shapley values on the more direct effect, and symmetric causal Shapley consider both for the more natural explanation.\relax }}{8}{figure.caption.5}}
\newlabel{fig:barplots}{{4}{8}{Asymmetric (conditional), (symmetric) causal and marginal Shapley values for two different days, one in October (brown) and one in December (gray) with more or less the same temperature of 13 degrees Celsius. Asymmetric Shapley values focus on the root cause, marginal Shapley values on the more direct effect, and symmetric causal Shapley consider both for the more natural explanation.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion}{8}{section.7}}
\citation{ribeiro2016should}
\citation{kusner2017counterfactual}
\citation{bhatt2020explainable}
\citation{gdpr2017}
\citation{kumar2020problems}
\citation{kaur2020interpreting}
\citation{edwards2017slave}
\citation{bhatt2020explainable}
\citation{sloman2005causal}
\citation{lombrozo2017causal}
\citation{rehder2003causal}
\citation{mittelstadt2019explaining}
\bibdata{shapleyrefs}
\bibcite{aas2019explaining}{1}
\bibcite{bhatt2020explainable}{2}
\bibcite{datta2016algorithmic}{3}
\bibcite{edwards2017slave}{4}
\bibcite{fanaee2013bikerental}{5}
\bibcite{frye2019asymmetric}{6}
\bibcite{gerstenberg2012noisy}{7}
\bibcite{icard2017normality}{8}
\bibcite{janzing2019feature}{9}
\bibcite{kahneman1986norm}{10}
\bibcite{kaur2020interpreting}{11}
\bibcite{kumar2020problems}{12}
\bibcite{kusner2017counterfactual}{13}
\bibcite{lauritzen2002chain}{14}
\bibcite{lewis1974causation}{15}
\bibcite{lipovetsky2001analysis}{16}
\bibcite{lombrozo2017causal}{17}
\bibcite{lundberg2020local}{18}
\bibcite{lundberg2018consistent}{19}
\bibcite{lundberg2017unified}{20}
\bibcite{merrick2019explanation}{21}
\bibcite{mittelstadt2019explaining}{22}
\bibcite{pearl1995causal}{23}
\bibcite{pearl2012calculus}{24}
\bibcite{rehder2003causal}{25}
\bibcite{ribeiro2016should}{26}
\bibcite{shapley1953value}{27}
\bibcite{sloman2005causal}{28}
\bibcite{sober1988apportioning}{29}
\bibcite{spellman1997crediting}{30}
\bibcite{vstrumbelj2014explaining}{31}
\bibcite{gdpr2017}{32}
\bibcite{wachter2017counterfactual}{33}
\bibstyle{plain}
