\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{lundberg2020local}
\citation{shapley1953value}
\citation{lipovetsky2001analysis}
\citation{vstrumbelj2014explaining}
\citation{lundberg2017unified}
\citation{ribeiro2016should}
\citation{sloman2005causal}
\citation{lombrozo2017causal}
\citation{sober1988apportioning}
\citation{gerstenberg2012noisy}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{wachter2017counterfactual}
\citation{vstrumbelj2014explaining}
\citation{datta2016algorithmic}
\citation{lundberg2017unified}
\citation{aas2019explaining}
\citation{janzing2019feature}
\citation{datta2016algorithmic}
\citation{pearl2012calculus}
\citation{lundberg2020local}
\citation{frye2019asymmetric}
\citation{aas2019explaining}
\citation{datta2016algorithmic}
\citation{janzing2019feature}
\citation{lundberg2020local}
\citation{lauritzen2002chain}
\citation{shapley1953value}
\@writefile{toc}{\contentsline {section}{\numberline {2}A causal interpretation of Shapley values}{2}{section.2}}
\newlabel{sec:interpretation}{{2}{2}{A causal interpretation of Shapley values}{section.2}{}}
\newlabel{eq:efficiency}{{1}{2}{A causal interpretation of Shapley values}{equation.2.1}{}}
\newlabel{eq:contperm}{{2}{2}{A causal interpretation of Shapley values}{equation.2.2}{}}
\citation{pearl1995causal}
\citation{shapley1953value}
\citation{aas2019explaining}
\citation{lundberg2018consistent}
\citation{datta2016algorithmic}
\citation{janzing2019feature}
\citation{lundberg2020local}
\citation{janzing2019feature}
\citation{datta2016algorithmic}
\citation{janzing2019feature}
\citation{lundberg2020local}
\citation{frye2019asymmetric}
\citation{frye2019asymmetric}
\newlabel{eq:valuedef}{{3}{3}{A causal interpretation of Shapley values}{equation.2.3}{}}
\newlabel{eq:shapperm}{{4}{3}{A causal interpretation of Shapley values}{equation.2.4}{}}
\citation{merrick2019explanation}
\citation{kahneman1986norm}
\citation{merrick2019explanation}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Direct and indirect Shapley values for four causal models with the same observational distribution over features (such that $\mathbb  {E}[X_1] = \mathbb  {E}[X_2] = 0$ and $\mathbb  {E}[X_2|x_1] = \alpha x_1$), yet a different causal structure. We assume a linear model that happens to ignore the first feature: $f(x_1,x_2) = \beta x_2$. The bottom table gives for each of the four causal models on the left the marginal, conditional, and causal Shapley values, where the latter two are further split up in symmetric and asymmetric. Each letter in the bottom table corresponds to one of the patterns of direct and indirect effects detailed in the top table: `direct' ({\em  D}, only direct effects), `evenly split' ({\em  E}, credit for an indirect effect split evenly between the features), and `root cause' ({\em  R}, all credit for the indirect effect goes to the root cause).\relax }}{4}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:fourmodels}{{1}{4}{Direct and indirect Shapley values for four causal models with the same observational distribution over features (such that $\expectation [X_1] = \expectation [X_2] = 0$ and $\expectation [X_2|x_1] = \alpha x_1$), yet a different causal structure. We assume a linear model that happens to ignore the first feature: $f(x_1,x_2) = \beta x_2$. The bottom table gives for each of the four causal models on the left the marginal, conditional, and causal Shapley values, where the latter two are further split up in symmetric and asymmetric. Each letter in the bottom table corresponds to one of the patterns of direct and indirect effects detailed in the top table: `direct' (\patd , only direct effects), `evenly split' (\pats , credit for an indirect effect split evenly between the features), and `root cause' (\pata , all credit for the indirect effect goes to the root cause).\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Decomposing Shapley values into direct and indirect effects}{4}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Shapley values for different causal structures}{4}{section.4}}
\newlabel{sec:toymodels}{{4}{4}{Shapley values for different causal structures}{section.4}{}}
\citation{datta2016algorithmic}
\citation{janzing2019feature}
\citation{lundberg2020local}
\citation{aas2019explaining}
\citation{frye2019asymmetric}
\citation{frye2019asymmetric}
\citation{spellman1997crediting}
\citation{icard2017normality}
\citation{lewis1974causation}
\citation{pearl2012calculus}
\citation{lauritzen2002chain}
\citation{lauritzen2002chain}
\@writefile{toc}{\contentsline {section}{\numberline {5}A practical implementation with causal chain graphs}{5}{section.5}}
\newlabel{eq:interventional}{{5}{5}{A practical implementation with causal chain graphs}{equation.5.5}{}}
\citation{lauritzen2002chain}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces From partial ordering to causal chain graph. Features on equal footing are combined into a fully connected chain component. How to handle interventions within each component depends on the generative process that best explains the (surplus) dependencies. In this example, the dependencies between $X_1$ and $X_2$ in chain component $\tau _1$ and $X_6$ and $X_7$ in $\tau _3$ are assumed to be the result of a common confounder. The surplus dependencies in $\tau _2$ are assumed to be caused by mutual interactions.\relax }}{6}{figure.caption.3}}
\newlabel{fig:chaingraph}{{2}{6}{From partial ordering to causal chain graph. Features on equal footing are combined into a fully connected chain component. How to handle interventions within each component depends on the generative process that best explains the (surplus) dependencies. In this example, the dependencies between $X_1$ and $X_2$ in chain component $\tau _1$ and $X_6$ and $X_7$ in $\tau _3$ are assumed to be the result of a common confounder. The surplus dependencies in $\tau _2$ are assumed to be caused by mutual interactions.\relax }{figure.caption.3}{}}
\newlabel{eq:chaininterventional}{{7}{6}{}{equation.5.6}{}}
\citation{pearl2012calculus}
\citation{aas2019explaining}
\citation{frye2019asymmetric}
\citation{aas2019explaining}
\citation{aas2019explaining}
\citation{frye2019asymmetric}
\citation{fanaee2013bikerental}
\citation{aas2019explaining}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Bike shares in Washington, D.C.\ in 2011-2012 (top left). Sina plot of causal Shapley values for a trained XGBoost model, where the top three date-related variables are considered to be a potential cause of the four weather-related variables (right). Scatter plots of marginal (MSV) versus causal Shapley values (CSV) for temperature ({\em  temp}) and one of the seasonal variables ({\em  cosyear}) show that MSVs almost purely explain the predictions based on temperature, whereas CSVs also give credit to season (bottom left).\relax }}{7}{figure.caption.4}}
\newlabel{fig:trendplot}{{3}{7}{Bike shares in Washington, D.C.\ in 2011-2012 (top left). Sina plot of causal Shapley values for a trained XGBoost model, where the top three date-related variables are considered to be a potential cause of the four weather-related variables (right). Scatter plots of marginal (MSV) versus causal Shapley values (CSV) for temperature ({\em temp}) and one of the seasonal variables ({\em cosyear}) show that MSVs almost purely explain the predictions based on temperature, whereas CSVs also give credit to season (bottom left).\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Illustration on real-world data}{7}{section.6}}
\citation{lundberg2017unified}
\citation{lundberg2020local}
\citation{pearl2018obesity}
\citation{ribeiro2016should}
\citation{kusner2017counterfactual}
\citation{gdpr2017}
\citation{kumar2020problems}
\citation{kaur2020interpreting}
\citation{edwards2017slave}
\citation{bhatt2020explainable}
\citation{sloman2005causal}
\citation{lombrozo2017causal}
\citation{rehder2003causal}
\citation{mittelstadt2019explaining}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion}{8}{section.7}}
\bibdata{shapleyrefs}
\bibcite{aas2019explaining}{1}
\bibcite{bhatt2020explainable}{2}
\bibcite{datta2016algorithmic}{3}
\bibcite{edwards2017slave}{4}
\bibcite{fanaee2013bikerental}{5}
\bibcite{frye2019asymmetric}{6}
\bibcite{gerstenberg2012noisy}{7}
\bibcite{icard2017normality}{8}
\bibcite{janzing2019feature}{9}
\bibcite{kahneman1986norm}{10}
\bibcite{kaur2020interpreting}{11}
\bibcite{kumar2020problems}{12}
\bibcite{kusner2017counterfactual}{13}
\bibcite{lauritzen2002chain}{14}
\bibcite{lewis1974causation}{15}
\bibcite{lipovetsky2001analysis}{16}
\bibcite{lombrozo2017causal}{17}
\bibcite{lundberg2020local}{18}
\bibcite{lundberg2018consistent}{19}
\bibcite{lundberg2017unified}{20}
\bibcite{merrick2019explanation}{21}
\bibcite{mittelstadt2019explaining}{22}
\bibcite{pearl1995causal}{23}
\bibcite{pearl2012calculus}{24}
\bibcite{pearl2018obesity}{25}
\bibcite{rehder2003causal}{26}
\bibcite{ribeiro2016should}{27}
\bibcite{shapley1953value}{28}
\bibcite{sloman2005causal}{29}
\bibcite{sober1988apportioning}{30}
\bibcite{spellman1997crediting}{31}
\bibcite{vstrumbelj2014explaining}{32}
\bibcite{gdpr2017}{33}
\bibcite{wachter2017counterfactual}{34}
\bibstyle{plain}
